{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b39933-1298-47d0-a141-dd40061e29e9",
   "metadata": {},
   "source": [
    "# Variational Autoencoders (VAE)\n",
    "\n",
    "Based on [`vae/train.py`](https://github.com/google/flax/blob/main/examples/vae/train.py) Flax example.\n",
    "\n",
    "Stochastic gradient variational Bayes (SGVB). VLB Monte Carlo estimate\n",
    "$$\n",
    "    \\hat{\\mathcal{L}}(\\boldsymbol\\theta, \\boldsymbol\\phi; {\\bf X}) = \\sum_{n=1}^N \\log p_{\\theta_x}({\\bf x}_n \\vert \\hat{\\bf z}_n) + \\log p_{\\theta_z}(\\hat{\\bf z}_n) - \\log p(\\hat{\\boldsymbol\\varepsilon}_n) + \\log d_\\phi(\\hat{\\boldsymbol\\varepsilon}_n, {\\bf x}_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "21be8924-ef86-4f79-aa97-cbda21544885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from flax.training import train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e74bf9-cccc-4748-9c48-9e073e7a98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13369b18-37b6-4b8d-a382-1541ce3a2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from jax's website\n",
    "# https://jax.readthedocs.io/en/latest/notebooks/Neural_Network_and_Data_Loading.html\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "class FlattenAndCast(object):\n",
    "  def __call__(self, pic):\n",
    "    return np.ravel(np.array(pic, dtype=jnp.float32))\n",
    "\n",
    "root = \"/tmp/mnist\"\n",
    "mnist_train = MNIST(root, download=True, train=True)\n",
    "mnist_test = MNIST(root, download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9739125c-6c42-4226-87d1-0d41effae08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = jnp.array(mnist_train.data)\n",
    "n_train, *_ = X_train.shape\n",
    "# \"Gaussanised\" MNIST\n",
    "Xf_train = X_train.reshape(-1, 28 ** 2)\n",
    "Xf_train = X_train / X_train.max()\n",
    "Xf_train = (Xf_train - Xf_train.mean()) / Xf_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a8aa33ef-2672-4ed5-abe2-e9cb0ff4fd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 352,
       "width": 351
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(314)\n",
    "key_sample, key = jax.random.split(key)\n",
    "ixs = jax.random.choice(key, n_train, (4,))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(5, 5))\n",
    "axs = axs.ravel()\n",
    "for ix, ax in zip(ixs, axs):\n",
    "    ax.imshow(Xf_train[ix].reshape(28, 28))\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a2b8109-9560-4fd6-a41d-cdf2b3f8c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    For the inference model p(z|x)\n",
    "    \"\"\"\n",
    "    # For the inference model p(z\\x)\n",
    "    latent_dim: int\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        z = nn.Dense(100)(x)\n",
    "        z = nn.relu(z)\n",
    "        z = nn.Dense(100)(z)\n",
    "        z = nn.relu(z)\n",
    "        mean_z = nn.Dense(self.latent_dim)(z)\n",
    "        logvar_z = nn.Dense(self.latent_dim)(z)\n",
    "        return mean_z, logvar_z\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    For the generative model\n",
    "    p(x,z) = p(x|z) * p(z)\n",
    "    \"\"\"\n",
    "    observed_dim: int\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, z):\n",
    "        x = nn.Dense(100)(z)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(100)(x)\n",
    "        x = nn.relu(x)\n",
    "        mean_x = nn.Dense(self.observed_dim)(x)\n",
    "        logvar_x = nn.Dense(self.observed_dim)(x)\n",
    "        return mean_x, logvar_x\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    latent_dim: int\n",
    "    observed_dim: int\n",
    "    \n",
    "    @staticmethod\n",
    "    def reparameterise(key, mean, logvar):\n",
    "        std = jnp.exp(logvar / 2)\n",
    "        eps = jax.random.normal(key, logvar.shape)\n",
    "        z = mean + eps * std\n",
    "        return z\n",
    "    \n",
    "    def setup(self):\n",
    "        # Called at .init\n",
    "        self.encoder = Encoder(self.latent_dim)\n",
    "        self.decoder = Decoder(self.observed_dim)\n",
    "    \n",
    "    def __call__(self, x, key_eps):\n",
    "        mean_z, logvar_z = self.encoder(x)\n",
    "        z = VAE.reparameterise(key_eps, mean_z, logvar_z)\n",
    "        mean_x, logvar_x = self.decoder(z)\n",
    "        return (mean_z, logvar_z), (mean_x, logvar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5ca337ea-e969-4a47-8c04-b1a35a6c431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_train_ixs(key, num_samples, batch_size):\n",
    "    \"\"\"\n",
    "    Obtain the training indices to be used in an epoch of\n",
    "    mini-batch optimisation.\n",
    "    \"\"\"\n",
    "    steps_per_epoch = num_samples // batch_size\n",
    "    \n",
    "    batch_ixs = jax.random.permutation(key, num_samples)\n",
    "    batch_ixs = batch_ixs[:steps_per_epoch * batch_size]\n",
    "    batch_ixs = batch_ixs.reshape(steps_per_epoch, batch_size)\n",
    "    \n",
    "    return batch_ixs\n",
    "\n",
    "\n",
    "def train_epoch(key, params, opt_step, X, y, sbatch_size, epoch):\n",
    "    num_samples = len(X)\n",
    "    batch_ixs = get_batch_train_ixs(key, num_samples, batch_size)\n",
    "    \n",
    "    for batch_ix in batch_ixs:\n",
    "        X_batch = X[batch_ix, ...]\n",
    "        y_batch = y[batch_ix, ...]\n",
    "        loss, params = train_step(params, opt_step, X_batch, y_batch)\n",
    "    \n",
    "    return params, opt_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9289d10-36a4-4ab7-9c95-16ae4c794058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 1.745846 , -1.3533316,  2.0788307], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE.reparameterise(key, 0, jnp.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "87d759e6-092a-4eb9-8362-6026603b0f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_dim = 28 ** 2\n",
    "latent_dim = 20\n",
    "batch_size = 200\n",
    "learning_rate = 1e-3\n",
    "batch_init = jnp.ones((batch_size, observed_dim))\n",
    "\n",
    "key_params_init, key_eps_init, key = jax.random.split(key, 3)\n",
    "model  = VAE(latent_dim, observed_dim)\n",
    "\n",
    "params_init = model.init(key_init, batch_init, key_eps_init)\n",
    "tx = optax.adam(learning_rate)\n",
    "\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params_init,\n",
    "    tx=tx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c1ce0-ed8d-4083-810b-548372739001",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "36b75db1-2fed-47cf-a3e4-0d11df4a740b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ScopeParamShapeError",
     "evalue": "Inconsistent shapes between value and initializer for parameter \"kernel\" in \"/encoder/Dense_0\": (784, 100), (28, 100). (https://flax.readthedocs.io/en/latest/flax.errors.html#flax.errors.ScopeParamShapeError)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScopeParamShapeError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36mVAE.__call__\u001b[0;34m(self, x, key_eps)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, key_eps):\n\u001b[0;32m---> 54\u001b[0m     mean_z, logvar_z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     z \u001b[38;5;241m=\u001b[39m VAE\u001b[38;5;241m.\u001b[39mreparameterise(key_eps, mean_z, logvar_z)\n\u001b[1;32m     56\u001b[0m     mean_x, logvar_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36mEncoder.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@nn\u001b[39m\u001b[38;5;241m.\u001b[39mcompact\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 10\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     z \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mrelu(z)\n\u001b[1;32m     12\u001b[0m     z \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m100\u001b[39m)(z)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/flax/linen/linear.py:183\u001b[0m, in \u001b[0;36mDense.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"Applies a linear transformation to the inputs along the last dimension.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m  The transformed input.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m inputs \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39masarray(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 183\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m kernel \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39masarray(kernel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    188\u001b[0m y \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mdot_general(inputs, kernel,\n\u001b[1;32m    189\u001b[0m                     (((inputs\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,), (\u001b[38;5;241m0\u001b[39m,)), ((), ())),\n\u001b[1;32m    190\u001b[0m                     precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/flax/core/scope.py:730\u001b[0m, in \u001b[0;36mScope.param\u001b[0;34m(self, name, init_fn, *init_args)\u001b[0m\n\u001b[1;32m    725\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m val, abs_val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(value_flat, abs_value_flat):\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;66;03m# NOTE: We could check dtype consistency here as well but it's\u001b[39;00m\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;66;03m# usefuleness is less obvious. We might intentionally change the dtype\u001b[39;00m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;66;03m# for inference to a half float type for example.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mshape(val) \u001b[38;5;241m!=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mshape(abs_val):\n\u001b[0;32m--> 730\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mScopeParamShapeError(name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_text,\n\u001b[1;32m    731\u001b[0m           jnp\u001b[38;5;241m.\u001b[39mshape(val), jnp\u001b[38;5;241m.\u001b[39mshape(abs_val))\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    733\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_mutable_collection(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mScopeParamShapeError\u001b[0m: Inconsistent shapes between value and initializer for parameter \"kernel\" in \"/encoder/Dense_0\": (784, 100), (28, 100). (https://flax.readthedocs.io/en/latest/flax.errors.html#flax.errors.ScopeParamShapeError)"
     ]
    }
   ],
   "source": [
    "model.apply(params_init, Xf_train[:10], key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79349fea-43a0-4e04-aeee-6f8cfb6b0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgvb_estimator(params):\n",
    "    \"\"\"\n",
    "    ** Loss function **\n",
    "    Stochastic Gradient Variational Bayes (SGVB)\n",
    "    estimator.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
